{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5d054df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy.random as random \n",
    "# TODO: Specify the seed so random things are generated again\n",
    "# %matplotlib qt\n",
    "\n",
    "from timer_module import TimerModule as TM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04431cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_to_absolute_event_time(relative_time_events, NUM_EVENTS):\n",
    "    # TODO: Change this to a simple cumsum on the first column\n",
    "    absolute_time_events = relative_time_events   \n",
    "    for i in range (1,NUM_EVENTS):\n",
    "        absolute_time_events[i][0] = relative_time_events[i-1][0] + relative_time_events[i][0]\n",
    "    return absolute_time_events  \n",
    "\n",
    "def activationAtIntervalEnd(timer, ramp_index, interval_length, c):\n",
    "    # Simulate DDM process for activation amount\n",
    "    # Change act to activation\n",
    "    act = timer.timers[ramp_index] * interval_length\n",
    "    for i in range (0, len(act)):\n",
    "        act[i] = act[i] + c * np.sqrt(act[i]) * np.random.normal(0, 1) * math.sqrt(interval_length)\n",
    "    return act\n",
    "\n",
    "def activationAtIntervalEndHierarchical(timer, ramp_index, interval_length, next_stimulus_type, c):\n",
    "    # Simulate DDM process for activation amount\n",
    "    # Change act to activation\n",
    "    delta = 0.5\n",
    "    '''\n",
    "    assigned_ramps = []\n",
    "    for timer_idx in ramp_index:\n",
    "        if timer.terminating_events[ramp_index] == next_stimulus_type:\n",
    "            assigned_ramps.append(timer_idx)\n",
    "    '''       \n",
    "    act = timer.timers[ramp_index] * interval_length\n",
    "    # print(f'ramp_index: {ramp_index}')\n",
    "    for i in range (0, len(act)):\n",
    "        act[i] = act[i] + c * np.sqrt(act[i]) * np.random.normal(0, 1) * math.sqrt(interval_length)\n",
    "    f_act = act * act\n",
    "    \n",
    "    # print(f'act: {act}')\n",
    "    \n",
    "    #for timer_act in act:\n",
    "    #    hier_act = timer_act + 1/((act.size)-1) * delta * f_act[act != timer_act].sum()\n",
    "\n",
    "    return act\n",
    "\n",
    "def update_and_reassign_ramps(timer, timer_values, timer_indices, next_stimulus_type, stimulus_type, external_idx, allocation_prob, NUM_RAMPS, RAMPS_PER_EVENT, sequence_code = '', v0=1.0, z = 1, bias = 1, plot = False):\n",
    "    # Frozen timers arent updated\n",
    "    for idx, value in zip(timer_indices, timer_values):\n",
    "        if idx in timer.frozen_ramps:\n",
    "            continue\n",
    "        \n",
    "        # Generate coin flip for random update\n",
    "        flip = random.random()\n",
    "\n",
    "        if idx in timer.free_ramps:\n",
    "            stim_type_y_plot_val = (NUM_RAMPS/2) - (NUM_RAMPS/4)\n",
    "            next_stim_type_y_plot_val = (NUM_RAMPS/2) - (NUM_RAMPS/4)\n",
    "        \n",
    "        \"\"\" \n",
    "        From all the ramps not idle who have either:\n",
    "            - S2=e_i and start<act<stop\n",
    "            - S2 = NA\n",
    "        Pick N randomly and update them for the interval s1->s2=e_i\n",
    "        \"\"\"\n",
    "        # If a timer is unassigned\n",
    "        if len(np.where(timer.terminating_events[np.where(timer.initiating_events == stimulus_type)] == next_stimulus_type)[0])>RAMPS_PER_EVENT:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if timer.terminating_events[idx] == -1:\n",
    "            if flip >=allocation_prob: # Update this to be a var, not a magic number\n",
    "                # if the timer has the appropriate terminating event, update the weight\n",
    "                if value > 1:\n",
    "                    ''' Early Update Rule '''\n",
    "                    timer_weight = earlyUpdateRule(value, timer.timerWeight(idx), timer.learningRate(idx))\n",
    "                   \n",
    "                    \n",
    "                else:\n",
    "                    ''' Late Update Rule '''\n",
    "                    timer_weight = lateUpdateRule(value, timer.timerWeight(idx), timer.learningRate(idx))\n",
    "                        \n",
    "                timer.terminating_events[idx] = next_stimulus_type\n",
    "                if idx in timer.free_ramps:\n",
    "                    timer.setTimerWeight(timer_weight, idx)\n",
    "                    timer.free_ramps = np.delete(timer.free_ramps, np.where(timer.free_ramps == idx))\n",
    "                    timer.initiating_events[idx] = stimulus_type\n",
    "                    \n",
    "            continue\n",
    "        \n",
    "        if timer.terminating_events[idx] == next_stimulus_type and timer.initiating_events[idx] == stimulus_type:\n",
    "            if flip>=.9:\n",
    "                if value > 1:\n",
    "                    ''' Early Update Rule '''\n",
    "                    #plot_early_update_rule(start_time, end_time, timer_weight, T, event_type, value)\n",
    "                    timer_weight = earlyUpdateRule(value, timer.timerWeight(idx), timer.learningRate(idx))\n",
    "                    # timer.setTimerWeight(timer_weight, idx)\n",
    "                        \n",
    "                else:\n",
    "                    ''' Late Update Rule '''\n",
    "                    timer_weight = lateUpdateRule(value, timer.timerWeight(idx), timer.learningRate(idx))\n",
    "                timer.setTimerWeight(timer_weight, idx) \n",
    "                \n",
    "def lateUpdateRule(vt, timer_weight, learning_rate, v0=1.0, z = 1, bias = 1):\n",
    "    \"\"\"\n",
    "    TODO: these are out of order\n",
    "    Include data types in each of these\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    v0: activation of IN unit\n",
    "    z: desired activation, threshold\n",
    "    Vt: timer unit activation\n",
    "    bias: bias of timer unit\n",
    "    timer_weight: the weight of the timer\n",
    "    Returns \n",
    "    -------\n",
    "    The corrected timer weight for the associated event\n",
    "    \"\"\"\n",
    "\n",
    "    drift = (timer_weight * v0)\n",
    "    d_A = drift * ((1-vt)/vt)\n",
    "    ret_weight = timer_weight + (learning_rate * d_A)\n",
    "    return ret_weight\n",
    "                \n",
    "def earlyUpdateRule(vt, timer_weight, learning_rate, v0=1.0, z = 1, bias = 1):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    v0: activation of IN unit\n",
    "    z: desired activation, threshold\n",
    "    Vt: timer unit activation\n",
    "    bias: bias of timer unit\n",
    "    timer_weight: the weight of the timer\n",
    "    Returns \n",
    "    -------\n",
    "    The corrected timer weight for the associated event\n",
    "    \"\"\"\n",
    "    drift = (timer_weight * v0)\n",
    "    d_A = drift * ((vt-z)/vt)\n",
    "    ret_weight = timer_weight - (learning_rate * d_A)\n",
    "    return ret_weight\n",
    "\n",
    "def start_threshold_time(act_at_interval_end, interval_length,START_THRESHOLD):\n",
    "    # Time of ramp hitting start threshold\n",
    "    # TODO: get rid of magic numbers here\n",
    "    angle = np.arctan(act_at_interval_end/interval_length)\n",
    "    beta = 3.14159 - (1.5708 + angle)\n",
    "    return START_THRESHOLD * np.tan(3.14159 - (1.5708 + angle))\n",
    "\n",
    "def stop_threshold_time(act_at_interval_end, interval_length,STOP_THRESHOLD):\n",
    "    # Time of ramp hitting stop threshold\n",
    "    angle = np.arctan(act_at_interval_end/interval_length)\n",
    "    beta = 3.14159 - (1.5708 + angle)\n",
    "    return STOP_THRESHOLD * np.tan(3.14159 - (1.5708 + angle))\n",
    "\n",
    "def generate_responses(interval_length, dt, num_samples):\n",
    "    num_samples = int(interval_length / dt)\n",
    "    responses = np.random.exponential(1, num_samples)\n",
    "    return responses\n",
    "\n",
    "\n",
    "def respond(timer_value, event_time, next_event, START_THRESHOLD, STOP_THRESHOLD, dt, num_samples, K, idx):\n",
    "    # Given all ramp vaues, respond when K are between start and stop range\n",
    "    # K is a global declared later on, tyically == 5\n",
    "    \n",
    "    # Find start threshold times for each ramp\n",
    "    start_threshold_times = start_threshold_time(timer_value, next_event-event_time, START_THRESHOLD)\n",
    "    start_threshold_times += event_time\n",
    "    start_threshold_times.sort()\n",
    "    start_threshold_times = np.vstack((start_threshold_times, np.ones(len(start_threshold_times)))).T\n",
    "    \n",
    "    # Find stop threshold times for each ramp\n",
    "    stop_threshold_times = stop_threshold_time(timer_value, next_event-event_time, STOP_THRESHOLD)\n",
    "    stop_threshold_times += event_time\n",
    "    stop_threshold_times.sort()\n",
    "    stop_threshold_times = np.vstack((stop_threshold_times, (-1* np.ones(len(stop_threshold_times))))).T\n",
    "    \n",
    "    # Zip start and stop times\n",
    "    start_stop_pairs = np.vstack((start_threshold_times, stop_threshold_times))\n",
    "    start_stop_pairs = start_stop_pairs[start_stop_pairs[:, 0].argsort()]\n",
    "\n",
    "    # TODO: Preallocate memory instead of initializing an empty list\n",
    "    responses = []\n",
    "    response_periods = []\n",
    "    k = 0\n",
    "    k_o = 0 # Old value of k\n",
    "    \n",
    "    # Form list of start and stop events, sorted by time (a1, sig1, a2, a3, sig2, sig3 etc)\n",
    "    # Loop through all, if start event, k++, else, k--\n",
    "    # Identify all periods of k > K\n",
    "    # Fill with Poisson seq (samples then add the start time to all of them)\n",
    "    # once theyre greater than the boundary where they stop, throw them out\n",
    "    for jdx, time in enumerate(start_stop_pairs):\n",
    "        k+=time[1]\n",
    "        # print(f'k: {k} \\t time: {time[0]}')\n",
    "        # We're entering a response period\n",
    "        if k_o < K and k >= K:\n",
    "            response_period_start = time[0]\n",
    "        if k_o >=K and k < K:\n",
    "            response_period_end = time[0]\n",
    "            response_periods.append([response_period_start, response_period_end])\n",
    "        k_o+=time[1]\n",
    "    \n",
    "    r = list(generate_responses(next_event-event_time, dt, num_samples))\n",
    "    r.insert(0, event_time)\n",
    "    r=list(np.cumsum(r))\n",
    "    # print('===')\n",
    "    # print(f'{event_time} / {next_event}')\n",
    "    for response_period in response_periods:\n",
    "        responses.extend([i for i in r if (i>response_period[0] and i<response_period[1] and i<next_event and i>event_time)])\n",
    "        \n",
    "    \n",
    "    # responses and ax1.text(responses[0],1.2,str(idx))\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2df79226",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x, amp=20, ceiling=1):\n",
    "    return ceiling / (1 + np.exp(-amp * x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49932874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(parameters, plot=True):\n",
    "    dt = parameters[\"dt\"]\n",
    "    N_EVENT_TYPES= parameters[\"N_EV_TYPES\"] # Number of event types (think, stimulus A, stimulus B, ...)\n",
    "    Y_LIM=2 # Vertical plotting limit\n",
    "    NOISE=parameters[\"NOISE\"] # Internal noise - timer activation\n",
    "    LEARNING_RATE=parameters[\"lr\"] # Default learning rate for timers\n",
    "    ALLOCATION_PROB = parameters[\"allocation_prob\"]\n",
    "    STANDARD_INTERVAL=20 # Standard interval duration \n",
    "    K = parameters[\"k\"] # Amount of timers that must be active to respond\n",
    "    \n",
    "    RR_est_tau = 200\n",
    "    \n",
    "    # hill climbing params\n",
    "    START_THRESHOLD=parameters[\"start_thresh\"]# Response start threshold\n",
    "    STOP_THRESHOLD=parameters[\"stop_thresh\"] # Response stop threshold\n",
    "    c = 0.1 # noise for iteration, separate from internal neural noise\n",
    "    baseline_noise = 0.5\n",
    "    noise_scale = 1\n",
    "    scale = 100\n",
    "    reward_vals = [0]\n",
    "    R_hat = R_delay = 1.0\n",
    "    R_hat_vals = [R_hat]\n",
    "    R_delay_vals = [R_delay]\n",
    "    \n",
    "    start_hat = start_delay = START_THRESHOLD\n",
    "    stop_hat = stop_delay = STOP_THRESHOLD\n",
    "    \n",
    "    start_hat_vals = []\n",
    "    start_delay_vals = []\n",
    "    \n",
    "    stop_hat_vals = []\n",
    "    stop_delay_vals = []\n",
    "    \n",
    "    R_hat_dot_delay = 0\n",
    "    R_hat_dot_dot_delay = 0\n",
    "    R_hat_dot_delay_vals = []\n",
    "    start_hat_dot_vals = []\n",
    "    stop_hat_dot_vals = []\n",
    "    R_hat_dot_vals = []\n",
    "    R_hat_dot_dot_vals = []\n",
    "    noise_vals = [baseline_noise]\n",
    "    \n",
    "    path = [(START_THRESHOLD, STOP_THRESHOLD)]\n",
    "    tau_iteration = 10\n",
    "    \n",
    "    # End iteration params\n",
    "    PLOT_FREE_TIMERS=False\n",
    "    ERROR_ANALYSIS_RESPONSES=[]\n",
    "    BEAT_THE_CLOCK = False\n",
    "    colors = [[1,0,0], [0,1,0], [0,0,1], [1,1,0], [0,1,1], [1,0,1],[.46,.03,0], [.1,.3,.2], [.2,.7,.2], [.5,.3,.6], [.7,.3,.4]]# list(mcolors.CSS4_COLORS) # Color support for events\n",
    "    ALPHABET_ARR = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','AA','BB','CC'] # For converting event types into letters \n",
    "    RESPONSE_THRESHOLD_LEARNING_RATE = .6\n",
    "    NUM_RAMPS = parameters[\"num_ramps\"]\n",
    "    RAMPS_PER_EVENT = parameters[\"ramps_per_event\"]\n",
    "    reward_window_plot = 1600\n",
    "    reward_window_sim = 1600\n",
    "    x_lb = np.linspace(-reward_window_plot * dt,0, reward_window_plot)\n",
    "    exp_weighted_average = np.exp(x_lb * .01)\n",
    "    \n",
    "    event_data = []\n",
    "    cur_RR = 0\n",
    "    old_RR = 0\n",
    "    expand = True \n",
    "    contract = False\n",
    "    random_seq = False\n",
    "    seq_length = 3\n",
    "\n",
    "    # Initialize events\n",
    "    if random_seq:\n",
    "        random_samples = TM.getSamples(seq_length, num_normal = 3, seed = 12, scale_beg = 20, scale_end = 50)\n",
    "        event_data = [[0,0,0]]\n",
    "        for sample in random_samples:\n",
    "            event_data.append([sample[0], sample[1], sample[2]])\n",
    "            \n",
    "        HOUSE_LIGHT_ON = [*range(0,seq_length-1,1)] + [*range(seq_length,(seq_length*2)-1,1)] + [*range(seq_length*2,(seq_length*3)-3,1)] + [*range(seq_length*3,(seq_length*4)-3,1)]\n",
    "        event_data = TM.getEvents(num_samples=seq_length, num_normal = 2, deviation=2, num_exp = 0, repeat = 3, scale_beg = 20, scale_end=30)\n",
    "        \n",
    "    else:\n",
    "        HOUSE_LIGHT_ON = [*range(0,1,1)] + [*range(2,3,1)] + [*range(4,5,1)] + [*range(6,7,1)] +  [*range(8,9,1)] + [*range(10,11,1)] + [*range(12,13,1)] + [*range(14,15,1)] + [*range(16,17,1)] + [*range(18,19,1)] + [*range(20,21,1)] + [*range(22,23,1)] #[*range(9,10,1)] + [*range(11,12,1)] + [*range(13,14,1)] +[*range(13,14,1)]\n",
    "        event_data = np.asarray([[0,1,1], [50,0,0], [25,1,1],\n",
    "                              [50,0,0], [25,1,1], [50,0,0], \n",
    "                              [25,1,1], [50,0,0], [25,1,1], \n",
    "                              [50,0,0], [25,1,1], [50,0,0], \n",
    "                              [25,1,1], [50,0,0], [25,1,1], \n",
    "                              [50,0,0], [25,1,1], [50,0,0],\n",
    "                              [25,1,1], [50,0,0], [25,1,1],\n",
    "                              [50,0,0], [25,1,1], [50,0,0],\n",
    "                              [25,1,1], [50,0,0], [25,1,1],\n",
    "                              [50,0,0], [25,1,1], [50,0,0],\n",
    "                              [25,1,1], [50,0,0], [25,1,1],\n",
    "                              [25,1,1], [50,0,0], [25,1,1],\n",
    "                              [25,1,1], [50,0,0], [25,1,1]])                        \n",
    "    \n",
    "    # TODO: Make start threhsolds an array of values\n",
    "    seq_len =  4\n",
    "    repeat_num = 3\n",
    "    penalty=.1\n",
    "\n",
    "    NUM_EVENTS = len(event_data) \n",
    "    btc_reward=np.empty(NUM_EVENTS)\n",
    "\n",
    "    error_arr = np.zeros(NUM_EVENTS)\n",
    "    event_data = relative_to_absolute_event_time(event_data, NUM_EVENTS)\n",
    "    event_data[0][2] = event_data[seq_len][2]\n",
    "\n",
    "    # Last event, time axis for plotting        \n",
    "    T = event_data[HOUSE_LIGHT_ON[-1]+1][0]\n",
    "    \n",
    "    # Timer with 100 (or however many you want) ramps, all initialized to be very highly weighted (n=1)\n",
    "    timer=TM(1,NUM_RAMPS)\n",
    "    if plot:\n",
    "        simple_learning_fig = plt.figure(figsize=(8,4))\n",
    "        # simple_learning_fig.suptitle('Simple Learning Sequence', fontsize=16)\n",
    "        ax1 = simple_learning_fig.add_subplot(311)\n",
    "        ax2 = simple_learning_fig.add_subplot(312, sharex = ax1)\n",
    "        ax3 = simple_learning_fig.add_subplot(313, sharex = ax1)\n",
    "        # ax4 = simple_learning_fig.add_subplot(314)\n",
    "    \n",
    "        ax1.set_ylim([0,Y_LIM])\n",
    "        ax1.set_xlim([0,T])\n",
    "    \n",
    "        ax2.set_ylim([0,1])\n",
    "        ax2.set_xlim([0,T])\n",
    "        ax3.set_xlim([0,T])\n",
    "\n",
    "    reward_arr_plot = np.zeros(int(event_data[HOUSE_LIGHT_ON[-1]+1][0] / dt))\n",
    "\n",
    "    timer_plot_legend_free = {}\n",
    "    timer_plot_legend_assigned = {}\n",
    "\n",
    "    # Initialize a reward arr that has a small amount of reward at each time step\n",
    "    reward_arr = np.zeros(int(event_data[HOUSE_LIGHT_ON[-1]+1][0]/dt))\n",
    "    if plot:\n",
    "        reward_x_axis = np.linspace(0,event_data[HOUSE_LIGHT_ON[-1]+1][0]/dt,reward_arr.shape[0])\n",
    "\n",
    "    # Define hidden states\n",
    "#     hidden_states = [175, 325, 475]\n",
    "#     for hidden_state in hidden_states:\n",
    "#         reward_arr[int(hidden_state/dt)] = 1\n",
    "        \n",
    "    # For event, add a large amount of reward at the event and a little right before it \n",
    "    for index, event in enumerate(event_data[1:]):\n",
    "        if index in HOUSE_LIGHT_ON or (index) in HOUSE_LIGHT_ON:\n",
    "            if int(event[0]/dt) < reward_arr.shape[0]:\n",
    "                reward_arr[int(event[0]/dt)] = 1\n",
    "                exp_arr = np.exp(-.5 * np.arange(0, 20, dt))[::-1]\n",
    "                reward_arr[int(event[0]/dt) - exp_arr.shape[0]:int(event[0]/dt)] = exp_arr\n",
    "\n",
    "    reward_arr[0] = 0 \n",
    "        \n",
    "#     if plot:\n",
    "#         for state in hidden_states:\n",
    "#             ax2.plot(state, .9, marker = '*', color='r', label=\"hidden state\")\n",
    "        \n",
    "    ''' Simulation Start '''\n",
    "    # At each event e_i\n",
    "    reward_est_vals = np.zeros(8750)\n",
    "    run_twice = 2\n",
    "    reward_estimation = [0]\n",
    "    for idx, event in enumerate(event_data[:HOUSE_LIGHT_ON[-1]]):\n",
    "        path.append((START_THRESHOLD, STOP_THRESHOLD))\n",
    "        \n",
    "        house_light = idx in HOUSE_LIGHT_ON\n",
    "        event_time = event[0]\n",
    "        event_type = int(event[1])\n",
    "        stimulus_type = int(event[2])\n",
    "        next_event = event_data[idx+1][0]\n",
    "        next_stimulus_type=int(event_data[idx+1][2])\n",
    "        \n",
    "        # Plot event times and labels\n",
    "        if idx < (NUM_EVENTS - 1):\n",
    "            if plot:\n",
    "                ax1.text(event[0],2.1,ALPHABET_ARR[int(event_data[idx+1][2])])\n",
    "                ax1.vlines(event_time, 0,Y_LIM, label=\"v\", color=colors[next_stimulus_type])\n",
    "                \n",
    "        if house_light:\n",
    "            # Plot house light bar\n",
    "            if plot:\n",
    "                house_light_bar = ax1.plot([event_time, next_event], [1.9, 1.9], 'k-', lw=4)  \n",
    "                ax1.plot([event_time, next_event], [1.9, 1.9], 'k-', lw=4)  \n",
    "            # Look forward to all other intervals before house light turns off and start updating weights\n",
    "            house_light_idx = idx + 1\n",
    "            house_light_interval = True\n",
    "            tau=200\n",
    "            while house_light_interval:\n",
    "                # If the next interval is in the house light period\n",
    "                if house_light_idx-1 in HOUSE_LIGHT_ON: \n",
    "                    # Get next event time and stimulus type\n",
    "                    next_house_light_event_time = event_data[house_light_idx][0]\n",
    "                    next_house_light_stimulus_type = event_data[house_light_idx][2]\n",
    "                    \n",
    "                    # All indices of ramps active by initiating event\n",
    "                    initiating_active_indices = np.where(timer.initiating_events == stimulus_type)\n",
    "                    \n",
    "                    # All initiating and free ramp indices\n",
    "                    active_ramp_indices = np.append(initiating_active_indices, timer.free_ramps)\n",
    "                    \n",
    "                    house_light_timer_value = activationAtIntervalEnd(timer, active_ramp_indices, next_house_light_event_time - event_time, NOISE)\n",
    "                    house_light_hierarchical_value = activationAtIntervalEndHierarchical(timer, initiating_active_indices, next_house_light_stimulus_type, next_house_light_event_time - event_time, NOISE)\n",
    "                    house_light_responding_values = activationAtIntervalEnd(timer, initiating_active_indices, next_house_light_event_time - event_time, NOISE)\n",
    "                    \n",
    "                    active_timer_value = activationAtIntervalEndHierarchical(timer, active_ramp_indices, next_house_light_stimulus_type, next_house_light_event_time - event_time, NOISE)\n",
    "                    \n",
    "                    if BEAT_THE_CLOCK:\n",
    "                        if not (event_time==0):\n",
    "                            response_time = beat_the_clock_threshold_time(active_timer_value, event_time, next_house_light_event_time, ax1, idx)\n",
    "                            reward = beat_the_clock_reward(next_house_light_event_time, response_time)\n",
    "                            ax1.hlines(START_THRESHOLD,event_time,next_house_light_event_time, color=\"green\", alpha=0.8)\n",
    "                            \n",
    "                            # TODO: This is code smell\n",
    "                            START_THRESHOLD = change_response_threshold(START_THRESHOLD, RESPONSE_THRESHOLD_LEARNING_RATE, btc_reward, reward)\n",
    "                            \n",
    "                            btc_reward[idx]=reward\n",
    "                    \n",
    "                    if idx > 0:\n",
    "                        responses = respond(house_light_responding_values, event_time, next_house_light_event_time, START_THRESHOLD, STOP_THRESHOLD, dt, seq_length, K, idx)\n",
    "                        if plot:\n",
    "                            ax1.plot(responses, np.ones(len(responses)), 'x')  \n",
    "                            \n",
    "                        if run_twice>0 and len(responses) > 0:\n",
    "                            run_twice-=1\n",
    "                            \n",
    "                        reward = reward_arr[[int(r/dt) for r in responses]]\n",
    "                        reward_vals.append(reward)\n",
    "                        \n",
    "                        # Iteration start\n",
    "                        if all(np.isnan(x) for x in reward):\n",
    "                            R = 0\n",
    "                        else:\n",
    "                            R = R_hat\n",
    "                            \n",
    "                        # QUESTION: Reward is an array, for now i average its vals, should we do something diff?\n",
    "                        # switch this to the reward rate estimator \n",
    "                        \n",
    "                        start_hat_dot = (1/tau_iteration) * (START_THRESHOLD - start_hat)\n",
    "                        start_hat_delay = (1/tau_iteration) * (start_hat - start_delay)\n",
    "                        \n",
    "                        stop_hat_dot = (1/tau_iteration) * (STOP_THRESHOLD - stop_hat)\n",
    "                        stop_hat_delay = (1/tau_iteration) * (stop_hat - stop_delay)\n",
    "                        \n",
    "                        start_hat += (start_hat_dot * dt)\n",
    "                        start_delay += (start_hat_delay*dt)\n",
    "                        \n",
    "                        stop_hat += (stop_hat_dot * dt)\n",
    "                        stop_delay += (stop_hat_delay*dt)\n",
    "                        \n",
    "                        start_hat_vals.append(start_hat)\n",
    "                        start_delay_vals.append(start_delay)\n",
    "                        \n",
    "                        stop_hat_vals.append(stop_hat)\n",
    "                        stop_delay_vals.append(stop_delay)\n",
    "                        \n",
    "                        start_hat_dot = start_hat - start_delay\n",
    "                        start_hat_dot_vals.append(start_hat_dot)\n",
    "                        \n",
    "                        stop_hat_dot = stop_hat - stop_delay\n",
    "                        stop_hat_dot_vals.append(stop_hat_dot)\n",
    "                        # print(reward)\n",
    "                        R_hat_dot = (1/tau) * (R - R_hat)\n",
    "                        R_dot_delay = (1/tau) * (R_hat - R_delay)\n",
    "                        \n",
    "                        R_hat += (R_hat_dot*dt)\n",
    "                        R_delay += (R_dot_delay*dt)\n",
    "                        \n",
    "                        R_hat_vals.append(R_hat)\n",
    "                        R_delay_vals.append(R_delay)\n",
    "                        \n",
    "                        R_hat_dot = R_hat - R_delay\n",
    "                        R_hat_dot_vals.append(R_hat_dot)\n",
    "                        \n",
    "                        R_hat_dot_dot_delay = (1/(.25*tau)) * (R_hat_dot - R_hat_dot_delay)\n",
    "                        R_hat_dot_delay += R_hat_dot_dot_delay * dt\n",
    "                        \n",
    "                        R_hat_dot_dot = R_hat_dot - R_hat_dot_delay\n",
    "                        \n",
    "                        ceiling = 0.1\n",
    "                        start_dot_dt = sigmoid(start_hat_dot * R_hat_dot, amp=10, ceiling=ceiling) - (-.5 * ceiling)\n",
    "                        stop_dot_dt = sigmoid(stop_hat_dot * R_hat_dot, amp=10, ceiling=ceiling) - (-.5 * ceiling)\n",
    "\n",
    "                        c = baseline_noise + max(0,(1-abs(R_hat_dot))) * R_hat_dot_dot * noise_scale\n",
    "                        if params['surface_demo'] == False:\n",
    "                            START_THRESHOLD += (start_dot_dt*dt) + c * np.random.normal(0,np.sqrt(dt))\n",
    "                            STOP_THRESHOLD += (stop_dot_dt*dt) + c * np.random.normal(0,np.sqrt(dt))\n",
    "                        \n",
    "                        # Iteration end\n",
    "                        pos_reward = np.where(reward > 0)[0]\n",
    "                        \n",
    "                        for i,r in enumerate(reward):\n",
    "                            if int(responses[i]/dt) < reward_arr_plot.shape[0]:\n",
    "                                reward_arr_plot[int(responses[i]/dt)] = r - penalty\n",
    "                               \n",
    "                        for i in range(1, reward_arr_plot.shape[0]):\n",
    "                            R_t = reward_estimation[i-1] + ((dt * (-reward_estimation[i-1]/tau) + reward_arr_plot[i]/tau))\n",
    "                            reward_estimation.append(R_t)\n",
    "                        \n",
    "                        if idx == 1:\n",
    "                            old_RR = np.mean(reward_estimation[:-50])\n",
    "                        \n",
    "                        # hill-climbing for reward/responding boundaries\n",
    "                        if idx > 1:\n",
    "                            cur_RR = np.mean(reward_estimation[:-50])\n",
    "                            if params['surface_demo'] == False:\n",
    "                                STOP_THRESHOLD += .2 * ((cur_RR-old_RR)/dt) # expand\n",
    "                                START_THRESHOLD -= .2 * ((cur_RR-old_RR)/dt) # contract\n",
    "\n",
    "                                if random.random() < .5: # randomness param\n",
    "                                    STOP_THRESHOLD += .2 * random.uniform(-1,1)\n",
    "                                    START_THRESHOLD -= .2 * random.uniform(-1,1)\n",
    "                            old_RR = cur_RR\n",
    "                        \n",
    "                        if plot:\n",
    "                            ax1.plot([event_time, next_house_light_event_time], [START_THRESHOLD, START_THRESHOLD], color='green')\n",
    "                            ax1.plot([event_time, next_house_light_event_time], [STOP_THRESHOLD, STOP_THRESHOLD], color='red') \n",
    "                            ax2.plot(responses,reward, marker='x', color = 'g')\n",
    "                   \n",
    "                    for i in range(int(event_time/dt)+1, int(next_house_light_event_time/dt)): # int(event_data[idx+1][0]/dt)):  #\n",
    "                        R_t = reward_est_vals[i-1] + ((dt * (-reward_est_vals[i-1]/tau) + reward_arr_plot[i]/tau))\n",
    "                        reward_est_vals[i] = R_t\n",
    "                        \n",
    "                        \n",
    "                    update_and_reassign_ramps(timer, house_light_timer_value, active_ramp_indices, next_house_light_stimulus_type, stimulus_type, idx, ALLOCATION_PROB, NUM_RAMPS, RAMPS_PER_EVENT)\n",
    "                    if plot:\n",
    "                        for value in house_light_hierarchical_value:\n",
    "                            ax1.plot([next_house_light_event_time], [value], marker='o',c=colors[next_stimulus_type], alpha=0.2) \n",
    "                    for i, val in zip(active_ramp_indices, house_light_timer_value):\n",
    "                        if timer.terminating_events[i] == next_house_light_stimulus_type and timer.initiating_events[i] == stimulus_type or i in timer.free_ramps:\n",
    "                            if i in timer.free_ramps:\n",
    "                                if plot:\n",
    "                                    timer_plot_legend_free[stimulus_type] = ax1.plot([event_time,next_house_light_event_time], [0, val], linestyle='--', c=colors[next_stimulus_type])\n",
    "                            \n",
    "                            else:\n",
    "                                if (val<STOP_THRESHOLD and val>START_THRESHOLD):\n",
    "                                    if plot:\n",
    "                                        timer_plot_legend_assigned[stimulus_type] = ax1.plot([event_time,next_house_light_event_time], [0, val],   c=colors[next_stimulus_type])\n",
    "                                        ax1.plot([next_house_light_event_time], [val], marker='o', c=colors[next_stimulus_type], markeredgecolor='black', markeredgewidth=1, alpha=0.2) \n",
    "                                \n",
    "                                \n",
    "                    # Contiue to the next event in the house light interval\n",
    "                    house_light_idx+=1\n",
    "                else:\n",
    "                    house_light_interval=False\n",
    "        else:\n",
    "            for i in range(int(event_time/dt), int(event_data[idx+1][0]/dt)):\n",
    "                if i > reward_est_vals.shape[0] - 1:\n",
    "                    break\n",
    "                else:\n",
    "                    R_t = reward_est_vals[i-1]\n",
    "                    reward_est_vals[i:] = R_t\n",
    "\n",
    "    window_size = 100\n",
    "\n",
    "\n",
    "    threshold_times = []\n",
    "    if plot:\n",
    "        ax1.set_ylim([0,Y_LIM])\n",
    "        ax1.set_xlim([0,400])\n",
    "        ax1.set_ylabel(\"Activation\")\n",
    "        ax1.set_xlabel(\"Time\")\n",
    "\n",
    "\n",
    "    # reward_sliding_windows = np.lib.stride_tricks.sliding_window_view(reward_arr_plot, window_size)\n",
    "\n",
    "    reward_arr_x = np.linspace(0,int(event_data[HOUSE_LIGHT_ON[-1]+1][0]), reward_arr_plot.shape[0])\n",
    "    if plot:\n",
    "        ax2.plot(reward_arr_x, reward_arr, label=\"reward\")\n",
    "\n",
    "\n",
    "\n",
    "    # reward_sliding_windows_vals = np.zeros(reward_arr_plot.shape[0])\n",
    "\n",
    "    # for i in range(window_size):\n",
    "    #     reward_sliding_windows_vals[i] =  np.sum(reward_arr_plot[:i] * kernel[:i])\n",
    "        \n",
    "    #     if i == 0:  \n",
    "    #         reward_sliding_windows_vals[-1] = np.sum(reward_arr_plot[-1:]) # * kernel[:1])\n",
    "    #     else:\n",
    "    #         reward_sliding_windows_vals[-i] = np.sum(reward_arr_plot[-i:]) # * kernel[:i])\n",
    "\n",
    "    def smooth(y, box_pts):\n",
    "        box = np.ones(box_pts)/box_pts\n",
    "        y_smooth = np.convolve(y, box, mode='full')\n",
    "        return y_smooth\n",
    "\n",
    "    def moving_average(a, n=3) :\n",
    "        ret = np.cumsum(a, dtype=float)\n",
    "        ret[n:] = ret[n:] - ret[:-n]\n",
    "        return ret[n - 1:] / n\n",
    "    # ax3.plot(reward_arr_x, reward_est_vals, linestyle='--')\n",
    "    ''' Newest reward rate estimation ''' \n",
    "    \n",
    "    reward_estimation = [0]\n",
    "    tau = 200\n",
    "    #     for i in range(1, reward_arr_plot.shape[0]):\n",
    "    #         R_t = reward_estimation[i-1] + ((dt * (-reward_estimation[i-1]/tau) + reward_arr_plot[i]/tau))\n",
    "    #         reward_estimation.append(R_t)\n",
    "    reward_estimation = reward_est_vals\n",
    "    if plot:  \n",
    "        # ax3.plot(reward_arr_x, reward_estimation)\n",
    "        ax3.plot(reward_arr_x, reward_est_vals, linestyle='--')\n",
    "    \n",
    "    average_reward = np.mean(reward_est_vals)\n",
    "    # print(np.mean(reward_arr_plot)\n",
    "    # print(f\"Average Reward: {average_reward}\")\n",
    "    # plt.show()\n",
    "    return average_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f52317e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"dt\":0.1,\n",
    "              \"N_EV_TYPES\":3,\n",
    "              \"NOISE\":0.01,\n",
    "              \"lr\": 0.8,\n",
    "              \"k\":2,\n",
    "              \"start_thresh\":.8,\n",
    "              \"stop_thresh\":1.1,\n",
    "              \"num_ramps\":60,\n",
    "              \"ramps_per_event\":3,\n",
    "              \"allocation_prob\":.9,\n",
    "              \"surface_demo\": True\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0997063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DONE, was noise: Figure out why the plotted line always ends at y = 1 \n",
    "# Simple surface estimate by averaging multiple runs with varying start/stop thresholds\n",
    "# DONE: Change to use reward rate estimator in each hill climbing iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1596d88",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[7], line 332\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(parameters, plot)\u001b[0m\n\u001b[1;32m    329\u001b[0m         timer_plot_legend_free[stimulus_type] \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mplot([event_time,next_house_light_event_time], [\u001b[38;5;241m0\u001b[39m, val], linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m, c\u001b[38;5;241m=\u001b[39mcolors[next_stimulus_type])\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (val\u001b[38;5;241m<\u001b[39mSTOP_THRESHOLD \u001b[38;5;129;01mand\u001b[39;00m val\u001b[38;5;241m>\u001b[39mSTART_THRESHOLD):\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m plot:\n\u001b[1;32m    334\u001b[0m             timer_plot_legend_assigned[stimulus_type] \u001b[38;5;241m=\u001b[39m ax1\u001b[38;5;241m.\u001b[39mplot([event_time,next_house_light_event_time], [\u001b[38;5;241m0\u001b[39m, val],   c\u001b[38;5;241m=\u001b[39mcolors[next_stimulus_type])\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "print(main(params, plot=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cde4f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate grid for the 2D space\n",
    "start_vals = np.linspace(0, 2, 5)\n",
    "stop_vals = np.linspace(0, 2, 5)\n",
    "x_grid, y_grid = np.meshgrid(start_vals, stop_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b160ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0. , 0. , 0. , 0. , 0. ],\n",
       "       [0.5, 0.5, 0.5, 0.5, 0.5],\n",
       "       [1. , 1. , 1. , 1. , 1. ],\n",
       "       [1.5, 1.5, 1.5, 1.5, 1.5],\n",
       "       [2. , 2. , 2. , 2. , 2. ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e38b34",
   "metadata": {},
   "outputs": [],
   "source": [
    " np.vectorize(main)(x_grid, dt=dt, y=y_grid, scale=scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3de09ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {\"dt\":0.1,\n",
    "              \"N_EV_TYPES\":3,\n",
    "              \"NOISE\":0.01,\n",
    "              \"lr\": 0.8,\n",
    "              \"k\":2,\n",
    "              \"start_thresh\":.8,\n",
    "              \"stop_thresh\":1.1,\n",
    "              \"num_ramps\":60,\n",
    "              \"ramps_per_event\":3,\n",
    "              \"allocation_prob\":.9,\n",
    "              \"surface_demo\": True\n",
    "              }\n",
    "\n",
    "z_grid = []\n",
    "for row_idx, stop_row in enumerate(y_grid):\n",
    "    reward_row = []\n",
    "    for col_idx, stop in enumerate(stop_row):\n",
    "        start = x_grid[row_idx][col_idx]\n",
    "        params['start_thresh'] = start\n",
    "        params['stop_thresh'] = stop\n",
    "        reward = main(params, plot=False)\n",
    "        reward_row.append(reward)\n",
    "    z_grid.append(reward_row)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14f952c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "contour = plt.contourf(x_grid, y_grid, z_grid, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6b2d0145",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'initiating_active_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m             exp_arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m.5\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m20\u001b[39m, dt))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     26\u001b[0m             reward_arr[\u001b[38;5;28mint\u001b[39m(event[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39mdt) \u001b[38;5;241m-\u001b[39m exp_arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\u001b[38;5;28mint\u001b[39m(event[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39mdt)] \u001b[38;5;241m=\u001b[39m exp_arr\n\u001b[0;32m---> 28\u001b[0m house_light_responding_values \u001b[38;5;241m=\u001b[39m activationAtIntervalEnd(timer, \u001b[43minitiating_active_indices\u001b[49m, next_house_light_event_time \u001b[38;5;241m-\u001b[39m event_time, NOISE)\n\u001b[1;32m     29\u001b[0m responses \u001b[38;5;241m=\u001b[39m respond(house_light_responding_values, event_time, next_house_light_event_time, START_THRESHOLD, STOP_THRESHOLD, dt, seq_length, K, idx)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_twice\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(responses) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'initiating_active_indices' is not defined"
     ]
    }
   ],
   "source": [
    "timer=TM(1,100)\n",
    "\n",
    "HOUSE_LIGHT_ON = [*range(0,1,1)] + [*range(2,3,1)] + [*range(4,5,1)] + [*range(6,7,1)] +  [*range(8,9,1)] + [*range(10,11,1)] + [*range(12,13,1)] + [*range(14,15,1)] + [*range(16,17,1)] + [*range(18,19,1)] + [*range(20,21,1)] + [*range(22,23,1)] #[*range(9,10,1)] + [*range(11,12,1)] + [*range(13,14,1)] +[*range(13,14,1)]\n",
    "dt = 0.1    \n",
    "event_data = np.asarray([[0,1,1], [50,0,0], [25,1,1],\n",
    "                      [50,0,0], [25,1,1], [50,0,0], \n",
    "                      [25,1,1], [50,0,0], [25,1,1], \n",
    "                      [50,0,0], [25,1,1], [50,0,0], \n",
    "                      [25,1,1], [50,0,0], [25,1,1], \n",
    "                      [50,0,0], [25,1,1], [50,0,0],\n",
    "                      [25,1,1], [50,0,0], [25,1,1],\n",
    "                      [50,0,0], [25,1,1], [50,0,0],\n",
    "                      [25,1,1], [50,0,0], [25,1,1],\n",
    "                      [50,0,0], [25,1,1], [50,0,0],\n",
    "                      [25,1,1], [50,0,0], [25,1,1],\n",
    "                      [25,1,1], [50,0,0], [25,1,1],\n",
    "                      [25,1,1], [50,0,0], [25,1,1]])        \n",
    "reward_arr = np.zeros(int(event_data[HOUSE_LIGHT_ON[-1]+2][0]/dt))\n",
    "# For event, add a large amount of reward at the event and a little right before it \n",
    "for index, event in enumerate(event_data[1:]):\n",
    "    # print(f'index: {index}, event: {event}')\n",
    "    if index in HOUSE_LIGHT_ON or (index-1) in HOUSE_LIGHT_ON:\n",
    "        if int(event[0]/dt) < reward_arr.shape[0]:\n",
    "            reward_arr[int(event[0]/dt)] = 1\n",
    "            exp_arr = np.exp(-.5 * np.arange(0, 20, dt))[::-1]\n",
    "            reward_arr[int(event[0]/dt) - exp_arr.shape[0]:int(event[0]/dt)] = exp_arr\n",
    "\n",
    "house_light_responding_values = activationAtIntervalEnd(timer, initiating_active_indices, next_house_light_event_time - event_time, NOISE)\n",
    "responses = respond(house_light_responding_values, event_time, next_house_light_event_time, START_THRESHOLD, STOP_THRESHOLD, dt, seq_length, K, idx)\n",
    "                   \n",
    "\n",
    "if run_twice>0 and len(responses) > 0:\n",
    "    run_twice-=1\n",
    "\n",
    "reward = reward_arr[[int(r/dt) for r in responses]]\n",
    "reward_vals.append(reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
